%\documentclass{article}
%\usepackage[letterpaper,margin=2.1cm]{geometry}
%\usepackage{xcolor}
%\usepackage{fancyhdr}
%\usepackage{tgschola} % or any other font package you like

\documentclass[12pt]{article}
\usepackage{extsizes}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsxtra}
\usepackage{wasysym}
\usepackage{isomath}
\usepackage{mathtools}
\usepackage{txfonts}
\usepackage{upgreek}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{tensor}
\usepackage{pifont}
\usepackage[margin=15mm]{geometry}
\definecolor{color-1}{rgb}{0.26,0.26,0.26}
\definecolor{color-2}{rgb}{0.4,0.4,0.4}
\usepackage{extsizes}
\usepackage{tocbibind}
\usepackage{float}
\usepackage{flafter}
\usepackage{xcolor}
\usepackage{sectsty}
\usepackage[font=small, skip=0pt]{caption}
\usepackage{setspace}
\setstretch{1.1}
\usepackage{fancyhdr}

\usepackage{nopageno}

% Select the font
\usepackage{charter}


\usepackage[%
square,        % for square brackets
comma,         % use commas as separators
numbers,       % for numerical citations;
%sort           % orders multiple citations into the sequence in which they appear in the list of references;
sort&compress % as sort but in addition multiple numerical citations
% are compressed if possible (as 3-6, 15);
]{natbib}

\renewcommand{\bibfont}{\normalfont\footnotesize}
\usepackage{hyperref}
\hypersetup{
	colorlinks = true,
	citecolor = {blue}
}







\newcommand{\soptitle}{Reinforcement Learning Improves Edge Computing}
\newcommand{\yourname}{Iman Rahmati}
\newcommand{\youremail}{iman.rahmati@sharif.edu}
\newcommand{\yourweb}{\href{https://imanrht.github.io}{imanrht.github.io}}

\newcommand{\statement}[1]{\par\medskip
	\underline{\textcolor{blue}{\textbf{#1:}}}\space
}

%\usepackage[
%colorlinks,
%breaklinks,
%pdftitle={\yourname - \soptitle},
%pdfauthor={\yourname},
%urlcolor  = blue,
%citecolor = blue,
%anchorcolor = blue,
%unicode
%]{hyperref}


\usepackage{setspace}
\onehalfspacing

\begin{document}
	

	
%\pagestyle{fancy}
%\fancyhf{}
%\fancyhead[C]{%
%	\footnotesize\sffamily\vspace{8mm}
%	\textcolor{blue}{\href{mailto:iman.rahmati@sharif.edu}{Research Ideas, V0.1}}  \hfill
%	\textcolor{blue}{\href{https://imanrht.github.io/assets/images/CV_ImanRahmati.pdf}{20 Sep. 2024\vspace{2mm}}}}
%




\begin{center} 
	

	
	\vspace{-17mm}
	
	\large Iman Rahmati  \hfill Meta RL For MEC \vspace{1mm} \hrule
	
	\vspace{-1mm}
	
	
	
	\textcolor{white}{i} \\ \LARGE Meta-Reinforcement Learning for Optimized Task Scheduling in Heterogeneous Edge Computing Systems \vspace{6mm}\\
	
\end{center}
\vspace{-5mm}
\small

\noindent\textbf{\large Motivation:  }
\noindent
Meta DRL focuses on training agents that can quickly adapt to new tasks or environments with minimal additional learning \cite{beck2023survey}. It is designed for scenarios where agents face a wide variety of tasks, and the aim is to learn a policy that generalizes well across different tasks. The primary objective is to equip the agent with meta-knowledge, allowing it to efficiently adapt to new tasks by leveraging past learning experiences. In MEC, a meta-trained agent could adapt its offloading strategy efficiently when moving between different environments, quickly optimizing its offloading decisions in unfamiliar settings.


\vspace{3mm}



\noindent\textbf{\large Problem Statement: } Efficient task offloading is crucial to ensure seamless resource distribution in MEC.
Typically, the overall Resource Management process involves three layers of heterogeneous Resource scheduling decisions (\textbf{P1}, \textbf{P2}, \textbf{P3}), each of which performs in a specific collaboration manner. \vspace{-2mm}

\begin{itemize}
	
	\item \textbf{P1. Edge-cloud service placement} \cite{farhadi2021service}.  %In MEC systems, clouds have sufficient resources, while edge servers are resource-limited. 
	The cloud caches all services with sufficient storage space. Considering the storage limits of edge servers, only a subset of services can be placed in each edge server. Services can be migrated from a cloud to an edge or between edge servers, which requires efficient collaboration.\vspace{-2mm}
	
	\item\textbf{P2. Edge-edge computation offloading} \cite{han2022edgetuner}. The task offloading decision-making process focuses on efficiently distributing tasks among edge servers. Edge-edge collaborations enable edge servers to offload their computation workload to neighboring servers, ensuring better resource utilization. \vspace{-2mm}
	
	\item\textbf{P3. Intra-edge resource allocation} \cite{xiong2020resource}. On edge servers, there may be several tasks competing for resources among offloaded tasks on the same server. Intra edge there is a resource competition among offloaded tasks on the same server. Intra-edge resource allocation aims to determine how resources should be allocated to each offloaded task.
	
\end{itemize}

\vspace{0mm}

\noindent\textbf{\large Problem Model: } To apply Meta RL for address combination of sub-problems  \textbf{P1},  \textbf{P2}, and \textbf{P3}, each problem can be formulated as an individual MDP model. The MDP learning process should be decomposed into two parts: \textbf{learning a meta policy efficiently across all MDPs} and \textbf{learning a specific strategy for an MDP quickly based on the learned meta policy}.
\noindent

\vspace{5mm}

\noindent\textbf{\large Research Methodology:}

\begin{enumerate}  \item \textbf{Algorithm Design:} Developing a Multi-Agent Meta-Reinforcement Learning algorithm using techniques such as \textbf{Meta-Actor and Meta-Critic Networks} \cite{ding2023multiagent}, with a focus on global optimization in MEC.\vspace{-1mm}
	
	\item \textbf{Simulation Environment:} A simulated MEC environment will be developed using Python or a suitable simulation platform, where cloud and edge servers be able to cache services and distribute tasks in whole resources, under different network conditions. 
	
	\item \textbf{Key Challenges:}  (a) The meta-learned policy should work well across different, unseen tasks. (b) Balancing between exploration (learning new tasks) and exploitation (using learned knowledge). 
\end{enumerate}



\bibliographystyle{IEEEtranN} % IEEEtranN is the natbib compatible bst file
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{paper}




\end{document}


